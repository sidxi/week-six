# My (thought) process
* Immediate thought: I want to do the trans archives
* Initially searching for: New York City (initial idea: sonification piece with paris is burning slipped in)
  * URLS non-sequential, not manually c/ping over 300 urls
  * Tried to do it with the search 
  * Wget took forever, and also I just got a bunch of random stuff that didn’t actually correspond to what was in my search (like just random stuff from the internet)
*	Decided to move to a MUCH smaller collection; I really rapidly realized a lot of the stuff I wanted to do I would need to spend at _least_ a month on (at least, even just on the small things I wanted to do!) to properly clean it and analyze it
  *	Chose: [BWBB collection (1992-1993)](https://www.digitaltransgenderarchive.net/catalog?f%5Bcollection_name_ssim%5D%5B%5D=Boys+Will+Be+Boys+&page=1) 
  * I pulled the PDFs, and initially was planning on using OCR to clean them up & pull the text (which I did for the first one)
  *	While doing this: I realized that I should be naming my images something other than “output”
  
![renaming realization](https://github.com/sidxi/week-six/blob/master/Screenshots/Week6%20renaming%20realization.PNG)
  
  *	THEN I REALIZED! They’re PDFs babeyyy – I can c/p the text in a way that will make them easier to clean up after!
  * Then I converted them from scans into text files and cleaned them up (only able to do this within my week long timeframe because I was working with a small amount of documents)
    *	I chose not to use REGEX or open refine because I felt that those were useful when working with datasets – I hadn’t yet created a dataset 
  *	While I was cleaning up, it was tedious but I really found myself noticing themes in the text that I used while transforming my data for TwoTone later
*	TwoTone 	
    * How on earth do I do this
    *	First I went back to the dataset that Dr. Graham made for TwoTone to see what the appropriate formatting was
    * Initial doc was a MESS just trying to make sense of things
    * First tried to separate into themes – but because they weren’t even I had a lot of repeating notes and it wasn’t fun to work with musically, nor was it an effective communication of my data
    * Eventually realized my middle doc (all the themes in a row) actually did what I wanted aurally, so I pulled it out and put it in its own excel doc
       *	Shows the continuum of passing time, shows how the themes are part of the same “track” (body of text), shows how they emerged at different points and in multiple places
    *	I wanted to create connection between the past and the future. Something I really felt during my analysis was how these newsletters were creating a sense of welcoming/community for the people receiving them 
        *	When I was first transitioning, the space I went to was YouTube to find a community. A really big staple when I was using this space was the “voice on T comparison” videos. I pulled a few videos that were personally meaningful to me (had watched in the past), & some that just worked, and layered some of those voice moments on audacity
        * Videos I chose:
          * [Alex Bertie - TRANSGENDER: 2 YEARS ON TESTOSTERONE](https://www.youtube.com/watch?v=tb3b-mKxZm8)
          * [Chella Man - ONE YEAR ON TESTOSTERONE: Voice Updates](https://www.youtube.com/watch?v=PsjBGqTjWu4)
          * [CallmeLaddie - TWO YEARS ON TESTOSTERONE!! FtM Transition (Voice Comparison)](https://www.youtube.com/watch?v=Wu9D-K24Iaw)
          * [Skylar Kergil - FTM Transition: 4.5 years on Testosterone comparison!](https://www.youtube.com/watch?v=4Bk_AP_5y-0&t=186s)
        *	I wanted to layer the start & stop dates of those journeys to aurally show time passing differently for different people, just like I felt in the BWBB newsletters
*	Note: I could only have done this because I was working on such a small scale – I feel like I have been working to capture a “moment” in history

# Questions I asked
* Why is wget taking so long?

![wget q](https://github.com/sidxi/week-six/blob/master/Screenshots/Week6%20wget%20LONG.PNG)
